name: Test Suite

on:
  push:
    branches: [ main, develop, 'feature/**' ]
  pull_request:
    branches: [ main, develop ]

env:
  NODE_VERSION: '18.x'
  SOLIDITY_VERSION: '0.8.24'

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-type: [api, contracts, ml, quantum]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run ${{ matrix.test-type }} unit tests
      run: npm run test:unit:${{ matrix.test-type }}
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        flags: unit-${{ matrix.test-type }}
        files: ./coverage/lcov.info

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: harmony_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Setup test environment
      run: |
        cp .env.test .env
        npm run db:migrate:test
    
    - name: Run integration tests
      run: npm run test:integration
      env:
        DATABASE_URL: postgresql://testuser:testpass@localhost:5432/harmony_test
        REDIS_URL: redis://localhost:6379
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: test-results.json

  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Build application
      run: npm run build
    
    - name: Start test environment
      run: |
        docker-compose -f docker-compose.test.yml up -d
        npm run wait-for-services
    
    - name: Run E2E tests
      run: npm run test:e2e
    
    - name: Stop test environment
      if: always()
      run: docker-compose -f docker-compose.test.yml down
    
    - name: Upload E2E test videos
      uses: actions/upload-artifact@v3
      if: failure()
      with:
        name: e2e-videos
        path: cypress/videos

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Build for performance testing
      run: npm run build:perf
    
    - name: Run performance tests
      run: npm run test:performance
    
    - name: Validate >1000 TPS
      run: |
        TPS=$(cat reports/performance-report.json | jq '.summary.achievedTPS')
        if (( $(echo "$TPS < 1000" | bc -l) )); then
          echo "Performance test failed: TPS $TPS is less than 1000"
          exit 1
        fi
        echo "Performance test passed: TPS $TPS"
    
    - name: Upload performance reports
      uses: actions/upload-artifact@v3
      with:
        name: performance-reports
        path: reports/

  smart-contract-tests:
    name: Smart Contract Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Compile contracts
      run: npx hardhat compile
    
    - name: Run contract tests
      run: npx hardhat test
    
    - name: Run contract coverage
      run: npx hardhat coverage
    
    - name: Check contract sizes
      run: npx hardhat size-contracts
    
    - name: Run Slither analysis
      uses: crytic/slither-action@v0.3.0
      with:
        node-version: ${{ env.NODE_VERSION }}
        sarif: results.sarif
        fail-on: high
    
    - name: Upload Slither results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: results.sarif

  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    needs: [integration-tests, performance-tests]
    if: github.event_name == 'pull_request' && github.base_ref == 'main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Build application
      run: npm run build
    
    - name: Run load tests
      run: npm run test:load
    
    - name: Analyze load test results
      run: npm run analyze:load-test
    
    - name: Comment PR with results
      uses: actions/github-script@v6
      if: github.event_name == 'pull_request'
      with:
        script: |
          const fs = require('fs');
          const report = JSON.parse(fs.readFileSync('reports/load-test-summary.json', 'utf8'));
          
          const comment = `## Load Test Results
          
          - **Peak TPS**: ${report.peakTPS}
          - **Average Response Time**: ${report.avgResponseTime}ms
          - **95th Percentile**: ${report.p95}ms
          - **99th Percentile**: ${report.p99}ms
          - **Error Rate**: ${report.errorRate}%
          - **Max Concurrent Users**: ${report.maxConcurrentUsers}
          
          ${report.passed ? '✅ Load test passed!' : '❌ Load test failed!'}`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, performance-tests, smart-contract-tests]
    if: always()
    
    steps:
    - name: Check test results
      run: |
        if [ "${{ needs.unit-tests.result }}" != "success" ] || \
           [ "${{ needs.integration-tests.result }}" != "success" ] || \
           [ "${{ needs.e2e-tests.result }}" != "success" ] || \
           [ "${{ needs.performance-tests.result }}" != "success" ] || \
           [ "${{ needs.smart-contract-tests.result }}" != "success" ]; then
          echo "One or more test suites failed"
          exit 1
        fi
        echo "All test suites passed!"
    
    - name: Create test report
      uses: dorny/test-reporter@v1
      if: always()
      with:
        name: Test Results
        path: '**/test-results.xml'
        reporter: jest-junit